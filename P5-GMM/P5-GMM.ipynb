{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SWCON253] Machine Learning\n",
    "Teaching Assistant: Hyunmin Ban (hmban1996@khu.ac.kr)\n",
    "\n",
    "Professor: Hui Yong Kim (hykim.v@khu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5.A:  GMM을 이용한 밀도추정 (4점)\n",
    "\n",
    "### 학습목표\n",
    "- GMM 모델을 이용하여 밀도추정을 할 수 있다.\n",
    "- Scikit-Learn을 이용하여 모델 학습을 구현할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Scikit-Learn의 GMM을 이용하여 군집화를 학습해 봅니다.  \n",
    "Scikit-Learn에서 Gaussian Mixture 클래스 사용법을 제공하니 아래 링크를 참고하세요.  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- Imports\n",
    "- 1) 데이터 생성\n",
    "- 2) GMM 모델 구현, 학습, Decision Boundary 시각화 **<직접 구현>**\n",
    "\n",
    "**이번 실습에서 여러분은 `2)` 부분의 코드를 직접 작성합니다.**\n",
    "\n",
    "앞으로 대부분의 실습도 위와 같은 순서로 진행됩니다. 이번 실습을 통해 각 부분의 코드를 이해하고 다음 실습에 참고하도록합니다.\n",
    "\n",
    "\n",
    "### 점수\n",
    "- 모델 작성: 4점, `#<your code>` 한 부분 마다 1점.\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 생성\n",
    "랜덤하게 데이터를 생성하며 Trainset과 Testset으로 랜덤 샘플링하여 나누고 데이터셋이 어떤 분포로 생겼는지 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "X1, y1 = make_blobs(n_samples=1000, centers=((5, -4), (0, 0)), random_state=42)\n",
    "X1 = X1.dot(np.array([[0.37, 0.95], [0.73, 0.6]]))\n",
    "X2, y2 = make_blobs(n_samples=500, centers=1, random_state=42)\n",
    "X = np.r_[X1, X2]\n",
    "\n",
    "# 데이터를 훈련 데이터와 테스트 데이터로 분류\n",
    "# X_test는 P5.B에서 사용\n",
    "X_train, X_test = train_test_split(X, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 plot\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], '.', markersize=3)\n",
    "plt.title('Random Blobs for Training')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 plot\n",
    "plt.plot(X_test[:, 0], X_test[:, 1], '.', markersize=3)\n",
    "plt.title('Random Blobs for Test')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GMM 모델 구현, 학습, 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn의 GaussianMixture 이용하여 GMM을 학습해 봅니다.  \n",
    "GaussianMixture의 `n_components`를 이용하면 군집의 갯수를 정할 수 있습니다. 이번 실습에서는 3개로 합니다.  \n",
    "또한 GMM을 생성할 때 n_init을 10으로 설정해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm =  # <your code> Gaussian Mixture 생성\n",
    " # <your code> 훈련 데이터(X_train)를 이용하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_mixture(clusterer, X, show_centroid=True, show_contour=True, show_boundary=False):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    x, y = np.meshgrid(np.linspace(mins[0], maxs[0], num=1000),np.linspace(mins[1], maxs[1], num=1000))\n",
    "       \n",
    "    # Centroids 시각화\n",
    "    if show_centroid:\n",
    "        centroids = <your code> # <your code> to use the mean of each components to get the centroids\n",
    "        plt.scatter(centroids[:, 0], centroids[:, 1], marker='o', s=20, linewidths=8, color='w', zorder=10)\n",
    "        plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=20, linewidths=12, color='k', zorder=11) \n",
    "    \n",
    "    # 밀도 등고선 시각화\n",
    "    if show_contour:\n",
    "        Z = -<your code>(np.c_[x.ravel(), y.ravel()]) # <your code> to compute the likelihood of each sample\n",
    "        Z = Z.reshape(x.shape)\n",
    "        cntr = plt.contourf(x, y, Z, norm=LogNorm(vmin=1.0, vmax=40), levels=np.logspace(0, 2, 10))\n",
    "        plt.contour(x, y, Z, norm=LogNorm(vmin=1.0, vmax=40), levels=np.logspace(0, 2, 10), linewidths=1, colors='k')\n",
    "    \n",
    "    # 결정 경계 시각화\n",
    "    if show_boundary:\n",
    "        Z = <your code>(np.c_[x.ravel(), y.ravel()]) # <your code> to predict the labels\n",
    "        Z = Z.reshape(x.shape)\n",
    "        plt.contour(x, y, Z, linewidths=2, colors='r', linestyles='dashed')\n",
    "    \n",
    "    plt.xlabel(\"$f_1$\")\n",
    "    plt.ylabel(\"$f_2$\", rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plot_gaussian_mixture(gmm, X_train)\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], 'k.', markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5.B: 학습한 GMM (P5.A의 결과)를 이용한 새로운 샘플 분류 (2점)\n",
    "### 학습목표\n",
    "- 학습한 GMM 모델을 이용하여 새로운 데이터를 분류할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Scikit-Learn에서 Gaussian Mixture 클래스 사용법을 제공하니 아래 링크를 참고하세요.  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 1) 결정 경계 시각화\n",
    "- 2) 학습된 GMM을 이용하여 클래스 분류 **<직접 구현>**\n",
    "\n",
    "**이번 실습에서 여러분은 `1)` 부분의 코드를 직접 작성합니다.**\n",
    "\n",
    "앞으로 대부분의 실습도 위와 같은 순서로 진행됩니다. 이번 실습을 통해 각 부분의 코드를 이해하고 다음 실습에 참고하도록합니다.\n",
    "\n",
    "### 점수\n",
    "- 코드 작성: 2점, `#<your code>` 와 plot_gaussian_mixture의 결정 경계 코드를 각각 1점 부여\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 결정 경계 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터로 학습한 GMM을 바탕으로 결정 경계를 그립니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Decision Boundary 시각화\n",
    "# P5.A에서 학습한 gmm을 그대로 사용\n",
    "plot_gaussian_mixture(gmm, X_test, show_centroid=False, show_contour=False, show_boundary=True)\n",
    "\n",
    "# 테스트 데이터 시각화\n",
    "plt.plot(X_test[:, 0], X_test[:, 1], '.', markersize=4) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 학습된 GMM을 이용하여 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Decision Boundary 시각화\n",
    "plot_gaussian_mixture(gmm, X_test, show_centroid=False, show_contour=False, show_boundary=True)\n",
    "\n",
    "y = # <your code> to get the prediction\n",
    "\n",
    "# 테스트 데이터에 대해 Class 분류\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y[idx] == 0], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y[idx] == 0],\n",
    "            label='class 0', marker='x')\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y[idx] == 1], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y[idx] == 1],\n",
    "            label='class 1', marker='s')\n",
    "plt.scatter([i[0] for idx, i in enumerate(X_test) if y[idx] == 2], \n",
    "            [i[1] for idx, i in enumerate(X_test) if y[idx] == 2],\n",
    "            label='class 2', marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5.C: 학습한 GMM (P5.A의 결과)를 이용한 이상치 탐지 (4점)\n",
    "### 학습목표\n",
    "- 학습한 GMM 모델을 이용하여 이상치 탐지를 할 수 있다.\n",
    "\n",
    "### 실습내용\n",
    "Scikit-Learn에서 Gaussian Mixture 클래스 사용법을 제공하니 아래 링크를 참고하세요.  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "\n",
    "실습은 다음 순서로 진행됩니다.\n",
    "- 1) 밀도 임계값 지정 **<직접 구현>**\n",
    "- 2) 이상치 시각화 \n",
    "\n",
    "**이번 실습에서 여러분은 `1)` 부분의 코드를 직접 작성합니다.**\n",
    "\n",
    "앞으로 대부분의 실습도 위와 같은 순서로 진행됩니다. 이번 실습을 통해 각 부분의 코드를 이해하고 다음 실습에 참고하도록합니다.\n",
    "\n",
    "\n",
    "### 점수\n",
    "- 모델 작성: 4점, `#<your code>` 한 부분 마다 2점.\n",
    "\n",
    "`.ipynb 파일과 함께 .html 파일 (File -> export as -> HTML)도 함께 제출하세요. 하나만 제출할시 감점이 있습니다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier\n",
    "![Outlier](https://miro.medium.com/max/1400/1*w5HzgB5ekxQ6Nwmx5ggn8Q.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM을 이상치 탐지에 사용할 수 있습니다. 밀도가 낮은 지역에 있는 샘플을 이상치로 생각할 수 있습니다. 예를 들어 결함 제품의 비율이 4%라고 하면 밀도 임곗값을 이 값으로 지정하여 임계 밀도보다 낮은 지역에 있는 샘플을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 밀도 임계값 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습한 데이터에 대해 밀도 임계값을 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities = # <your code> to get the densities of the trained data\n",
    "density_threshold = np.percentile(densities, 4)\n",
    "anomalies = # <your code> to get the samples that are under the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 이상치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plot_gaussian_mixture(gmm, X_train)\n",
    "plt.plot(X_train[:, 0], X_train[:, 1], 'k.', markersize=4)\n",
    "plt.scatter(anomalies[:, 0], anomalies[:, 1], color='r', marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) 군집화와, 분류의 차이점은 무엇인가요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Gaussian Mixture Model의 장단점에 대해 설명하세요**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) GMM의 Covariance type를 다른 type ('tied', 'spherical', 'diag')로 바꿀 수 있습니다.  \n",
    "GMM에서 default로 사용하는 Covariance type는 'full'로 클러스터의 모양, 크기, 방향에 제약이 없습니다.  \n",
    "그러면 Covariance type를 바꾸면 클러스터가 어떻게 바뀌는지 설명하고 각 모양을 plot 하세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[답변작성]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
